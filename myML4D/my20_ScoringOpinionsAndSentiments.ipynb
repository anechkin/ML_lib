{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scoring Opinions and Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding How Machines Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = 'The quick brown fox jumps over the lazy dog.'\n",
    "text_2 = 'My dog is quick and can jump over fences.'\n",
    "text_3 = 'Your dog is so lazy that it sleeps all the day.'\n",
    "corpus = [text_1, text_2, text_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "vectorizer = text.CountVectorizer(binary=True).fit(corpus)\n",
    "vectorized_text = vectorizer.transform(corpus)\n",
    "print(vectorized_text.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 19, 'quick': 15, 'brown': 2, 'fox': 7, 'jumps': 11, 'over': 14, 'lazy': 12, 'dog': 5, 'my': 13, 'is': 8, 'and': 1, 'can': 3, 'jump': 10, 'fences': 6, 'your': 20, 'so': 17, 'that': 18, 'it': 9, 'sleeps': 16, 'all': 0, 'day': 4}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and Enhancing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 0 0 2 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "text_4 = 'A black dog just passed by but my dog is brown.'\n",
    "corpus.append(text_4)\n",
    "vectorizer = text.CountVectorizer().fit(corpus)\n",
    "vectorized_text = vectorizer.transform(corpus)\n",
    "print(vectorized_text.todense()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     brown: 0.095\n",
      "       dog: 0.126\n",
      "        my: 0.095\n",
      "        is: 0.077\n",
      "     black: 0.121\n",
      "      just: 0.121\n",
      "    passed: 0.121\n",
      "        by: 0.121\n",
      "       but: 0.121\n",
      "\n",
      "Summed values of a phrase: 1.0\n"
     ]
    }
   ],
   "source": [
    "TfidF = text.TfidfTransformer(norm='l1')\n",
    "tfidf = TfidF.fit_transform(vectorized_text)\n",
    "\n",
    "phrase = 3 # choose a number from 0 to 3\n",
    "total = 0\n",
    "for word in vectorizer.vocabulary_:\n",
    "    pos = vectorizer.vocabulary_[word]\n",
    "    value = list(tfidf.toarray()[phrase])[pos]\n",
    "    if value !=0:\n",
    "        print (\"%10s: %0.3f\" % (word, value))\n",
    "        total += value\n",
    "print ('\\nSummed values of a phrase: %0.1f' % total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the quick': 30, 'quick brown': 24, 'brown fox': 3, 'fox jumps': 9, 'jumps over': 15, 'over the': 21, 'the lazy': 29, 'lazy dog': 17, 'my dog': 19, 'dog is': 7, 'is quick': 11, 'quick and': 23, 'and can': 1, 'can jump': 6, 'jump over': 14, 'over fences': 20, 'your dog': 31, 'is so': 12, 'so lazy': 26, 'lazy that': 18, 'that it': 27, 'it sleeps': 13, 'sleeps all': 25, 'all the': 0, 'the day': 28, 'black dog': 2, 'dog just': 8, 'just passed': 16, 'passed by': 22, 'by but': 5, 'but my': 4, 'is brown': 10}\n"
     ]
    }
   ],
   "source": [
    "bigrams = text.CountVectorizer(ngram_range=(2,2))\n",
    "print (bigrams.fit(corpus).vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Amigo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "['love', 'sam', 'swim', 'time']\n",
      "[[1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vocab = ['Sam loves swimming so he swims all the time']\n",
    "vect = text.CountVectorizer(tokenizer=tokenize, \n",
    "                           stop_words='english')\n",
    "vec = vect.fit(vocab)\n",
    "\n",
    "sentence1 = vec.transform(['George loves swimming too!'])\n",
    "\n",
    "print (vec.get_feature_names())\n",
    "print (sentence1.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Textual Datasets from the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "try:\n",
    "    import urllib2 # Python 2.7.x\n",
    "except:\n",
    "    import urllib.request as urllib2 # Python 3.x\n",
    "\n",
    "wiki = \"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\"\n",
    "header = {'User-Agent': 'Mozilla/5.0'} \n",
    "query = urllib2.Request(wiki, headers=header)\n",
    "page = urllib2.urlopen(query)\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"table\", { \"class\" : \"wikitable sortable\" })\n",
    "final_table = list()\n",
    "for row in table.findAll('tr'):\n",
    "    cells = row.findAll(\"td\")\n",
    "    if len(cells) >=6:\n",
    "        v1 = cells[1].find(text=True)\n",
    "        v2 = cells[2].find(text=True)\n",
    "        v3 = cells[3].find(text=True)\n",
    "        v4 = cells[4].find(text=True)\n",
    "        v5 = cells[6].findAll(text=True)\n",
    "        #v5 = v5[2].split()[0]\n",
    "        final_table.append([v1, v2, v3, v4, v5])\n",
    "cols = ['City','State','Population_2014','Census_2010'\n",
    "        ,'Land_Area_Mile2']\n",
    "df = pd.DataFrame(final_table, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Population_2014</th>\n",
       "      <th>Census_2010</th>\n",
       "      <th>Land_Area_Mile2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td></td>\n",
       "      <td>8,622,698</td>\n",
       "      <td>8,175,133</td>\n",
       "      <td>[301.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td></td>\n",
       "      <td>3,999,759</td>\n",
       "      <td>3,792,621</td>\n",
       "      <td>[468.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td></td>\n",
       "      <td>2,716,450</td>\n",
       "      <td>2,695,598</td>\n",
       "      <td>[227.3 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston</td>\n",
       "      <td></td>\n",
       "      <td>2,312,717</td>\n",
       "      <td>2,100,263</td>\n",
       "      <td>[637.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td></td>\n",
       "      <td>1,626,078</td>\n",
       "      <td>1,445,632</td>\n",
       "      <td>[517.6 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td></td>\n",
       "      <td>1,580,863</td>\n",
       "      <td>1,526,006</td>\n",
       "      <td>[134.2 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td></td>\n",
       "      <td>1,511,946</td>\n",
       "      <td>1,327,407</td>\n",
       "      <td>[461.0 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Diego</td>\n",
       "      <td></td>\n",
       "      <td>1,419,516</td>\n",
       "      <td>1,307,402</td>\n",
       "      <td>[325.2 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dallas</td>\n",
       "      <td></td>\n",
       "      <td>1,341,075</td>\n",
       "      <td>1,197,816</td>\n",
       "      <td>[340.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>San Jose</td>\n",
       "      <td></td>\n",
       "      <td>1,035,317</td>\n",
       "      <td>945,942</td>\n",
       "      <td>[177.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austin</td>\n",
       "      <td></td>\n",
       "      <td>950,715</td>\n",
       "      <td>790,390</td>\n",
       "      <td>[312.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jacksonville</td>\n",
       "      <td></td>\n",
       "      <td>892,062</td>\n",
       "      <td>821,784</td>\n",
       "      <td>[747.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td></td>\n",
       "      <td>884,363</td>\n",
       "      <td>805,235</td>\n",
       "      <td>[46.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Columbus</td>\n",
       "      <td></td>\n",
       "      <td>879,170</td>\n",
       "      <td>787,033</td>\n",
       "      <td>[218.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fort Worth</td>\n",
       "      <td></td>\n",
       "      <td>874,168</td>\n",
       "      <td>741,206</td>\n",
       "      <td>[342.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td></td>\n",
       "      <td>863,002</td>\n",
       "      <td>820,445</td>\n",
       "      <td>[361.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td></td>\n",
       "      <td>859,035</td>\n",
       "      <td>731,424</td>\n",
       "      <td>[305.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Seattle</td>\n",
       "      <td></td>\n",
       "      <td>724,745</td>\n",
       "      <td>608,660</td>\n",
       "      <td>[83.8 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Denver</td>\n",
       "      <td></td>\n",
       "      <td>704,621</td>\n",
       "      <td>600,158</td>\n",
       "      <td>[153.3 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Washington</td>\n",
       "      <td></td>\n",
       "      <td>693,972</td>\n",
       "      <td>601,723</td>\n",
       "      <td>[61.1 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Boston</td>\n",
       "      <td></td>\n",
       "      <td>685,094</td>\n",
       "      <td>617,594</td>\n",
       "      <td>[48.3 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>El Paso</td>\n",
       "      <td></td>\n",
       "      <td>683,577</td>\n",
       "      <td>649,121</td>\n",
       "      <td>[256.8 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Detroit</td>\n",
       "      <td></td>\n",
       "      <td>673,104</td>\n",
       "      <td>713,777</td>\n",
       "      <td>[138.8 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nashville</td>\n",
       "      <td></td>\n",
       "      <td>667,560</td>\n",
       "      <td>601,222</td>\n",
       "      <td>[475.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Memphis</td>\n",
       "      <td></td>\n",
       "      <td>652,236</td>\n",
       "      <td>646,889</td>\n",
       "      <td>[317.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Portland</td>\n",
       "      <td></td>\n",
       "      <td>647,805</td>\n",
       "      <td>583,776</td>\n",
       "      <td>[133.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td></td>\n",
       "      <td>643,648</td>\n",
       "      <td>579,999</td>\n",
       "      <td>[606.3 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td></td>\n",
       "      <td>641,676</td>\n",
       "      <td>583,756</td>\n",
       "      <td>[134.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Louisville</td>\n",
       "      <td></td>\n",
       "      <td>621,349</td>\n",
       "      <td>597,337</td>\n",
       "      <td>[263.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Baltimore</td>\n",
       "      <td></td>\n",
       "      <td>611,648</td>\n",
       "      <td>620,961</td>\n",
       "      <td>[80.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Santa Maria</td>\n",
       "      <td></td>\n",
       "      <td>107,014</td>\n",
       "      <td>99,553</td>\n",
       "      <td>[22.8 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Hillsboro</td>\n",
       "      <td></td>\n",
       "      <td>106,894</td>\n",
       "      <td>91,611</td>\n",
       "      <td>[25.0 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Sandy Springs</td>\n",
       "      <td></td>\n",
       "      <td>106,739</td>\n",
       "      <td>93,853</td>\n",
       "      <td>[37.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Norwalk</td>\n",
       "      <td></td>\n",
       "      <td>106,084</td>\n",
       "      <td>105,549</td>\n",
       "      <td>[9.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Jurupa Valley</td>\n",
       "      <td></td>\n",
       "      <td>106,028</td>\n",
       "      <td>0</td>\n",
       "      <td>[42.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Lewisville</td>\n",
       "      <td></td>\n",
       "      <td>106,021</td>\n",
       "      <td>95,290</td>\n",
       "      <td>[36.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Greeley</td>\n",
       "      <td></td>\n",
       "      <td>105,448</td>\n",
       "      <td>92,889</td>\n",
       "      <td>[47.8 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Davie</td>\n",
       "      <td></td>\n",
       "      <td>105,149</td>\n",
       "      <td>91,992</td>\n",
       "      <td>[34.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Green Bay</td>\n",
       "      <td></td>\n",
       "      <td>105,116</td>\n",
       "      <td>104,057</td>\n",
       "      <td>[45.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Tyler</td>\n",
       "      <td></td>\n",
       "      <td>104,991</td>\n",
       "      <td>96,900</td>\n",
       "      <td>[56.6 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>League City</td>\n",
       "      <td></td>\n",
       "      <td>104,903</td>\n",
       "      <td>83,560</td>\n",
       "      <td>[51.2 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Burbank</td>\n",
       "      <td></td>\n",
       "      <td>104,834</td>\n",
       "      <td>103,340</td>\n",
       "      <td>[17.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>San Mateo</td>\n",
       "      <td></td>\n",
       "      <td>104,748</td>\n",
       "      <td>97,207</td>\n",
       "      <td>[12.1 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Wichita Falls</td>\n",
       "      <td></td>\n",
       "      <td>104,747</td>\n",
       "      <td>104,553</td>\n",
       "      <td>[72.2 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>El Cajon</td>\n",
       "      <td></td>\n",
       "      <td>103,894</td>\n",
       "      <td>99,478</td>\n",
       "      <td>[14.5 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Rialto</td>\n",
       "      <td></td>\n",
       "      <td>103,562</td>\n",
       "      <td>99,171</td>\n",
       "      <td>[22.3 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Lakewood</td>\n",
       "      <td></td>\n",
       "      <td>102,682</td>\n",
       "      <td>92,843</td>\n",
       "      <td>[24.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Edison</td>\n",
       "      <td></td>\n",
       "      <td>102,450</td>\n",
       "      <td>99,967</td>\n",
       "      <td>[30.1 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Davenport</td>\n",
       "      <td></td>\n",
       "      <td>102,320</td>\n",
       "      <td>99,685</td>\n",
       "      <td>[62.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>South Bend</td>\n",
       "      <td></td>\n",
       "      <td>102,245</td>\n",
       "      <td>101,168</td>\n",
       "      <td>[41.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Woodbridge</td>\n",
       "      <td></td>\n",
       "      <td>101,965</td>\n",
       "      <td>99,585</td>\n",
       "      <td>[23.3 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Las Cruces</td>\n",
       "      <td></td>\n",
       "      <td>101,712</td>\n",
       "      <td>97,618</td>\n",
       "      <td>[76.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Vista</td>\n",
       "      <td></td>\n",
       "      <td>101,568</td>\n",
       "      <td>93,834</td>\n",
       "      <td>[18.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Renton</td>\n",
       "      <td></td>\n",
       "      <td>101,379</td>\n",
       "      <td>90,927</td>\n",
       "      <td>[23.4 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Sparks</td>\n",
       "      <td></td>\n",
       "      <td>100,888</td>\n",
       "      <td>90,264</td>\n",
       "      <td>[35.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Clinton</td>\n",
       "      <td></td>\n",
       "      <td>100,712</td>\n",
       "      <td>96,796</td>\n",
       "      <td>[28.1 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Allen</td>\n",
       "      <td></td>\n",
       "      <td>100,685</td>\n",
       "      <td>84,246</td>\n",
       "      <td>[27.1 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td></td>\n",
       "      <td>100,287</td>\n",
       "      <td>90,468</td>\n",
       "      <td>[71.7 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>San Angelo</td>\n",
       "      <td></td>\n",
       "      <td>100,119</td>\n",
       "      <td>93,200</td>\n",
       "      <td>[59.9 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Vacaville</td>\n",
       "      <td></td>\n",
       "      <td>100,032</td>\n",
       "      <td>92,428</td>\n",
       "      <td>[29.0 sq mi\n",
       "]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              City State Population_2014 Census_2010 Land_Area_Mile2\n",
       "0         New York            8,622,698\n",
       "  8,175,133\n",
       "  [301.5 sq mi\n",
       "]\n",
       "1      Los Angeles            3,999,759\n",
       "  3,792,621\n",
       "  [468.7 sq mi\n",
       "]\n",
       "2          Chicago            2,716,450\n",
       "  2,695,598\n",
       "  [227.3 sq mi\n",
       "]\n",
       "3          Houston            2,312,717\n",
       "  2,100,263\n",
       "  [637.5 sq mi\n",
       "]\n",
       "4          Phoenix            1,626,078\n",
       "  1,445,632\n",
       "  [517.6 sq mi\n",
       "]\n",
       "5     Philadelphia            1,580,863\n",
       "  1,526,006\n",
       "  [134.2 sq mi\n",
       "]\n",
       "6      San Antonio            1,511,946\n",
       "  1,327,407\n",
       "  [461.0 sq mi\n",
       "]\n",
       "7        San Diego            1,419,516\n",
       "  1,307,402\n",
       "  [325.2 sq mi\n",
       "]\n",
       "8           Dallas            1,341,075\n",
       "  1,197,816\n",
       "  [340.9 sq mi\n",
       "]\n",
       "9         San Jose            1,035,317\n",
       "    945,942\n",
       "  [177.5 sq mi\n",
       "]\n",
       "10          Austin              950,715\n",
       "    790,390\n",
       "  [312.7 sq mi\n",
       "]\n",
       "11    Jacksonville              892,062\n",
       "    821,784\n",
       "  [747.4 sq mi\n",
       "]\n",
       "12   San Francisco              884,363\n",
       "    805,235\n",
       "   [46.9 sq mi\n",
       "]\n",
       "13        Columbus              879,170\n",
       "    787,033\n",
       "  [218.5 sq mi\n",
       "]\n",
       "14      Fort Worth              874,168\n",
       "    741,206\n",
       "  [342.9 sq mi\n",
       "]\n",
       "15    Indianapolis              863,002\n",
       "    820,445\n",
       "  [361.5 sq mi\n",
       "]\n",
       "16       Charlotte              859,035\n",
       "    731,424\n",
       "  [305.4 sq mi\n",
       "]\n",
       "17         Seattle              724,745\n",
       "    608,660\n",
       "   [83.8 sq mi\n",
       "]\n",
       "18          Denver              704,621\n",
       "    600,158\n",
       "  [153.3 sq mi\n",
       "]\n",
       "19      Washington              693,972\n",
       "    601,723\n",
       "   [61.1 sq mi\n",
       "]\n",
       "20          Boston              685,094\n",
       "    617,594\n",
       "   [48.3 sq mi\n",
       "]\n",
       "21         El Paso              683,577\n",
       "    649,121\n",
       "  [256.8 sq mi\n",
       "]\n",
       "22         Detroit              673,104\n",
       "    713,777\n",
       "  [138.8 sq mi\n",
       "]\n",
       "23       Nashville              667,560\n",
       "    601,222\n",
       "  [475.9 sq mi\n",
       "]\n",
       "24         Memphis              652,236\n",
       "    646,889\n",
       "  [317.4 sq mi\n",
       "]\n",
       "25        Portland              647,805\n",
       "    583,776\n",
       "  [133.5 sq mi\n",
       "]\n",
       "26   Oklahoma City              643,648\n",
       "    579,999\n",
       "  [606.3 sq mi\n",
       "]\n",
       "27       Las Vegas              641,676\n",
       "    583,756\n",
       "  [134.4 sq mi\n",
       "]\n",
       "28      Louisville              621,349\n",
       "    597,337\n",
       "  [263.5 sq mi\n",
       "]\n",
       "29       Baltimore              611,648\n",
       "    620,961\n",
       "   [80.9 sq mi\n",
       "]\n",
       "..             ...   ...             ...         ...             ...\n",
       "281    Santa Maria              107,014\n",
       "     99,553\n",
       "   [22.8 sq mi\n",
       "]\n",
       "282      Hillsboro              106,894\n",
       "     91,611\n",
       "   [25.0 sq mi\n",
       "]\n",
       "283  Sandy Springs              106,739\n",
       "     93,853\n",
       "   [37.7 sq mi\n",
       "]\n",
       "284        Norwalk              106,084\n",
       "    105,549\n",
       "    [9.7 sq mi\n",
       "]\n",
       "285  Jurupa Valley              106,028\n",
       "          0\n",
       "   [42.9 sq mi\n",
       "]\n",
       "286     Lewisville              106,021\n",
       "     95,290\n",
       "   [36.7 sq mi\n",
       "]\n",
       "287        Greeley              105,448\n",
       "     92,889\n",
       "   [47.8 sq mi\n",
       "]\n",
       "288          Davie              105,149\n",
       "     91,992\n",
       "   [34.9 sq mi\n",
       "]\n",
       "289      Green Bay              105,116\n",
       "    104,057\n",
       "   [45.4 sq mi\n",
       "]\n",
       "290          Tyler              104,991\n",
       "     96,900\n",
       "   [56.6 sq mi\n",
       "]\n",
       "291    League City              104,903\n",
       "     83,560\n",
       "   [51.2 sq mi\n",
       "]\n",
       "292        Burbank              104,834\n",
       "    103,340\n",
       "   [17.4 sq mi\n",
       "]\n",
       "293      San Mateo              104,748\n",
       "     97,207\n",
       "   [12.1 sq mi\n",
       "]\n",
       "294  Wichita Falls              104,747\n",
       "    104,553\n",
       "   [72.2 sq mi\n",
       "]\n",
       "295       El Cajon              103,894\n",
       "     99,478\n",
       "   [14.5 sq mi\n",
       "]\n",
       "296         Rialto              103,562\n",
       "     99,171\n",
       "   [22.3 sq mi\n",
       "]\n",
       "297       Lakewood              102,682\n",
       "     92,843\n",
       "   [24.7 sq mi\n",
       "]\n",
       "298         Edison              102,450\n",
       "     99,967\n",
       "   [30.1 sq mi\n",
       "]\n",
       "299      Davenport              102,320\n",
       "     99,685\n",
       "   [62.9 sq mi\n",
       "]\n",
       "300     South Bend              102,245\n",
       "    101,168\n",
       "   [41.4 sq mi\n",
       "]\n",
       "301     Woodbridge              101,965\n",
       "     99,585\n",
       "   [23.3 sq mi\n",
       "]\n",
       "302     Las Cruces              101,712\n",
       "     97,618\n",
       "   [76.9 sq mi\n",
       "]\n",
       "303          Vista              101,568\n",
       "     93,834\n",
       "   [18.7 sq mi\n",
       "]\n",
       "304         Renton              101,379\n",
       "     90,927\n",
       "   [23.4 sq mi\n",
       "]\n",
       "305         Sparks              100,888\n",
       "     90,264\n",
       "   [35.9 sq mi\n",
       "]\n",
       "306        Clinton              100,712\n",
       "     96,796\n",
       "   [28.1 sq mi\n",
       "]\n",
       "307          Allen              100,685\n",
       "     84,246\n",
       "   [27.1 sq mi\n",
       "]\n",
       "308     Tuscaloosa              100,287\n",
       "     90,468\n",
       "   [71.7 sq mi\n",
       "]\n",
       "309     San Angelo              100,119\n",
       "     93,200\n",
       "   [59.9 sq mi\n",
       "]\n",
       "310      Vacaville              100,032\n",
       "     92,428\n",
       "   [29.0 sq mi\n",
       "]\n",
       "\n",
       "[311 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scoring and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts: 585\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, \n",
    "    categories = ['misc.forsale'],\n",
    "     remove=('headers', 'footers', 'quotes'), random_state=101)\n",
    "print ('Posts: %i' % len(dataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, \n",
    "            min_df=2, stop_words='english')\n",
    "tfidf = vectorizer.fit_transform(dataset.data)\n",
    "from sklearn.decomposition import NMF\n",
    "n_topics = 5\n",
    "nmf = NMF(n_components=n_topics, random_state=101).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "condition excellent asking offer best car old new sale 10 miles 000 tape cd power\n",
      "Topic #2:\n",
      "00 50 dos 20 10 15 cover 1st new 25 price man 40 shipping comics\n",
      "Topic #3:\n",
      "drive hard card floppy monitor meg ram disk motherboard vga modem brand scsi color internal\n",
      "Topic #4:\n",
      "email looking game games send interested mail thanks like edu good want package price list\n",
      "Topic #5:\n",
      "shipping vcr works stereo obo included amp plus great volume unc mathes gibbs radley remotes\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "n_top_words = 15\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "   print (\"Topic #%d:\" % (topic_idx+1),)\n",
    "   print (\" \".join([feature_names[i] for i in \n",
    "                    topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1075 1459  632 2463  740  888 2476 2415 2987   10 2305    1 3349  923\n",
      " 2680]\n"
     ]
    }
   ],
   "source": [
    "print (nmf.components_[0,:].argsort()[:-n_top_words-1:-1]) \n",
    "# Gets top words for topic 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition\n"
     ]
    }
   ],
   "source": [
    "print (vectorizer.get_feature_names()[1075]) \n",
    "# Transforms index 1075 back to text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analyzing reviews from e-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting in /Users/Amigo/anaconda3/anyaconda3/myGitrepo/ML_lib/myML4D\n",
      "\tunzipping /Users/Amigo/anaconda3/anyaconda3/myGitrepo/ML_lib/myML4D/amazon_cells_labelled.txt\n",
      "\tunzipping /Users/Amigo/anaconda3/anyaconda3/myGitrepo/ML_lib/myML4D/imdb_labelled.txt\n",
      "\tunzipping /Users/Amigo/anaconda3/anyaconda3/myGitrepo/ML_lib/myML4D/readme.txt\n",
      "\tunzipping /Users/Amigo/anaconda3/anyaconda3/myGitrepo/ML_lib/myML4D/yelp_labelled.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urllib2 # Python 2.7.x\n",
    "except:\n",
    "    import urllib.request as urllib2 # Python 3.x\n",
    "import requests, io, os, zipfile\n",
    "\n",
    "UCI_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip'\n",
    "response = requests.get(UCI_url)\n",
    "compressed_file = io.BytesIO(response.content)\n",
    "z = zipfile.ZipFile(compressed_file)\n",
    "print ('Extracting in %s' %  os.getcwd())\n",
    "for name in z.namelist():\n",
    "    filename = name.split('/')[-1]\n",
    "    nameOK = ('MACOSX' not in name and '.DS' not in name)\n",
    "    if filename and nameOK:\n",
    "            newfile = os.path.join(os.getcwd(), \n",
    "                                   os.path.basename(filename))\n",
    "            with open(newfile, 'wb') as f:\n",
    "                f.write(z.read(name))\n",
    "            print ('\\tunzipping %s' % newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = 'imdb_labelled.txt'\n",
    "data = pd.read_csv(dataset, header=None, sep=r\"\\t\", engine='python')\n",
    "data.columns = ['review','sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "corpus, test_corpus, y, yt = train_test_split(data.ix[:,0], data.ix[:,1], test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "vectorizer = text.CountVectorizer(ngram_range=(1,2), \n",
    "                    stop_words='english').fit(corpus)\n",
    "TfidF = text.TfidfTransformer()\n",
    "X = TfidF.fit_transform(vectorizer.transform(corpus))\n",
    "Xt = TfidF.transform(vectorizer.transform(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = {'C': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "clf = GridSearchCV(LinearSVC(loss='hinge', \n",
    "                    random_state=101), param_grid)\n",
    "clf = clf.fit(X, y)\n",
    "print (\"Best parameters: %s\" % clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 0.816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "solution = clf.predict(Xt)\n",
    "print(\"Achieved accuracy: %0.3f\" % \n",
    "      accuracy_score(yt, solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601    There is simply no excuse for something this p...\n",
      "32     This is the kind of money that is wasted prope...\n",
      "887    At any rate this film stinks, its not funny, a...\n",
      "668    Speaking of the music, it is unbearably predic...\n",
      "408         It really created a unique feeling though.  \n",
      "413         The camera really likes her in this movie.  \n",
      "138    I saw \"Mirrormask\" last night and it was an un...\n",
      "132    This was a poor remake of \"My Best Friends Wed...\n",
      "291                               Rating: 1 out of 10.  \n",
      "904    I'm so sorry but I really can't recommend it t...\n",
      "410    A world better than 95% of the garbage in the ...\n",
      "55     But I recommend waiting for their future effor...\n",
      "826    The film deserves strong kudos for taking this...\n",
      "100            I don't think you will be disappointed.  \n",
      "352                                    It is shameful.  \n",
      "171    This movie now joins Revenge of the Boogeyman ...\n",
      "814    You share General Loewenhielm's exquisite joy ...\n",
      "218    It's this pandering to the audience that sabot...\n",
      "168    Still, I do like this movie for it's empowerme...\n",
      "479                     Of course, the acting is blah.  \n",
      "31                      Waste your money on this game.  \n",
      "805    The only place good for this film is in the ga...\n",
      "127    My only problem is I thought the actor playing...\n",
      "613                                       Go watch it!  \n",
      "764                      This movie is also revealing.  \n",
      "107    I love Lane, but I've never seen her in a movi...\n",
      "674    Tom Wilkinson broke my heart at the end... and...\n",
      "30     There are massive levels, massive unlockable c...\n",
      "667                                    It is not good.  \n",
      "823    I struggle to find anything bad to say about i...\n",
      "739         What on earth is Irons doing in this film?  \n",
      "185                              Highly unrecommended.  \n",
      "621    A mature, subtle script that suggests and occa...\n",
      "462    Considering the relations off screen between T...\n",
      "595    Easily, none other cartoon made me laugh in a ...\n",
      "8                                   A bit predictable.  \n",
      "446    I like Armand Assante & my cable company's sum...\n",
      "449    I won't say any more - I don't like spoilers, ...\n",
      "715    Im big fan of RPG games too, but this movie, i...\n",
      "241    This would not even be good as a made for TV f...\n",
      "471    At no point in the proceedings does it look re...\n",
      "481    And, FINALLY, after all that, we get to an end...\n",
      "104                           Too politically correct.  \n",
      "522    Rating: 0/10 (Grade: Z) Note: The Show Is So B...\n",
      "174               This film has no redeeming features.  \n",
      "491    This movie creates its own universe, and is fa...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_corpus[yt!=solution])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
